{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taken from main.py. This specifies the model hyperparameters, trains the model and saves it in the models folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nrms import NRMS\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from train import train\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from nrms import NewsEncoder\n",
    "import torch.optim as optim\n",
    "from dataloader import create_dataloader\n",
    "from dataloader_validation import create_validation_dataloader\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "class Hyperparameters:\n",
    "    def __init__(self):\n",
    "        self.history_size = 30\n",
    "        self.title_size = 768\n",
    "        self.head_num = 16\n",
    "        self.head_dim = 16\n",
    "        self.attention_hidden_dim = 200\n",
    "        self.dropout = 0.2\n",
    "        self.learning_rate = 0.0001\n",
    "        self.negative_sampling_ratio = 4\n",
    "        self.newsencoder_output_dim = 256\n",
    "        self.dim_attention_later2 = 256\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "        self.seed = 123\n",
    "        self.weight_decay = 1e-4\n",
    "        self.num_of_rows_in_train = 1000\n",
    "# Usage\n",
    "hparams = Hyperparameters()\n",
    "\n",
    "# Load the data. Put data and contrastive vectors in tmp folder \n",
    "path_to_data = \"tmp/Data/ebnerd_small\"\n",
    "path_to_embeddings = \"tmp/Data/Ekstra_Bladet_contrastive_vector/Ekstra_Bladet_contrastive_vector\"\n",
    "\n",
    "dataloader_train = create_dataloader(Path(path_to_data), Path(path_to_embeddings),hparams, 32 )\n",
    "\n",
    "dataloader_validation = create_validation_dataloader(Path(path_to_data), Path(path_to_embeddings),hparams, 32 )\n",
    "\n",
    "\n",
    "# Initialize NRMS model\n",
    "news_encoder = NewsEncoder(hparams, units_per_layer=[512, 512, 512])\n",
    "nrms_model = NRMS(hparams, news_encoder)\n",
    "\n",
    "# Define  optimizer\n",
    "optimizer = optim.Adam(nrms_model.parameters(), lr=hparams.learning_rate, weight_decay=hparams.weight_decay)\n",
    "\n",
    "# Train the model\n",
    "train(nrms_model, dataloader_train, dataloader_validation, hparams.loss_func, optimizer, num_epochs=5, hparams=hparams)\n",
    "\n",
    "\n",
    "torch.save(nrms_model, \"models/nrms_model_5_epoch_10k.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taken from load_model_and_predict.py. This loads the before trained model and creates a predictions.txt for uploading to Codabench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nrms import NRMS\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from nrms import NewsEncoder\n",
    "from pathlib import Path\n",
    "from test_set_dataloader import create_test_set\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "class Hyperparameters:\n",
    "    def __init__(self):\n",
    "        self.history_size = 30\n",
    "        self.title_size = 768\n",
    "        self.head_num = 16\n",
    "        self.head_dim = 16\n",
    "        self.attention_hidden_dim = 200\n",
    "        self.dropout = 0.2\n",
    "        self.learning_rate = 0.0001\n",
    "        self.negative_sampling_ratio = 4\n",
    "        self.newsencoder_output_dim = 256\n",
    "        self.dim_attention_later2 = 256\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "        self.seed = 123\n",
    "        self.weight_decay = 1e-4\n",
    "        self.num_of_rows_in_train = 1000\n",
    "# Usage\n",
    "hparams = Hyperparameters()\n",
    "\n",
    "# Initialize NRMS model\n",
    "news_encoder = NewsEncoder(hparams, units_per_layer=[512, 512, 512])\n",
    "nrms_model = NRMS(hparams, news_encoder)\n",
    "\n",
    "# Load the model\n",
    "nrms_model = torch.load(\"models/nrms_model_5_epoch_10k.pth\")\n",
    "nrms_model.eval()\n",
    "\n",
    "# Load the data\n",
    "path_to_data = \"tmp/ebnerd_testset\"\n",
    "path_to_embeddings = \"tmp/Data/Ekstra_Bladet_contrastive_vector/Ekstra_Bladet_contrastive_vector\"\n",
    "\n",
    "test_data, article_embeddings_dict = create_test_set(Path(path_to_data), Path(path_to_embeddings),hparams)\n",
    "\n",
    "folder_name = Path(\"test\")\n",
    "path_to_txt = Path(\"submission_folders\" / folder_name)\n",
    "\n",
    "\n",
    "\n",
    "print(len(test_data))\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "results = []\n",
    "\n",
    "for impression_id, row in test_data.iterrows():\n",
    "    his_article_ids = row[\"his_article_ids\"]\n",
    "    article_ids_inview = row[\"article_ids_inview\"]\n",
    "\n",
    "    # Create row in tensor_data with index i and columns his_article_ids and article_ids_inview as tensors\n",
    "    his_article_embeddings = np.array([article_embeddings_dict[article_id] for article_id in his_article_ids], dtype=np.float32)\n",
    "    his_article_tensor = torch.tensor(his_article_embeddings)\n",
    "\n",
    "    article_ids_inview_embeddings = np.array(\n",
    "        [article_embeddings_dict[article_id] for article_id in article_ids_inview], dtype=np.float32)\n",
    "    article_ids_inview_tensor = torch.tensor(article_ids_inview_embeddings)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = nrms_model(his_article_tensor.unsqueeze(0), article_ids_inview_tensor.unsqueeze(0))\n",
    "        predictions = predictions.squeeze(0)\n",
    "        predictions = predictions.numpy()\n",
    "\n",
    "    labels = np.argsort(np.argsort(predictions)[::-1]) + 1\n",
    "    labels = labels.tolist()\n",
    "\n",
    "    # Add the labels to the DataFrame\n",
    "    results.append((impression_id, labels))\n",
    "\n",
    "    if len(results) % 10000 == 0:\n",
    "        print(f\"Processed {len(results)} rows out of {len(test_data)}\")\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"impression_id\", \"predictions\"])\n",
    "# Save the DataFrame to a parquet file\n",
    "results_df.to_parquet(path_to_txt / \"predictions.parquet\")\n",
    "\n",
    "with open(path_to_txt / \"predictions.txt\", \"w\") as f:\n",
    "    for impr_index, preds in tqdm(results):\n",
    "        preds = \"[\" + \",\".join([str(i) for i in preds]) + \"]\"\n",
    "        f.write(\" \".join([str(impr_index), preds]) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
